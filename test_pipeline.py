"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ML Data Pipeline

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python test_pipeline.py
"""

import asyncio
import json
from pathlib import Path

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤
print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤...")

try:
    from src.pipeline import (
        ETLProcessor, ETLConfig,
        LabelerAgent, LabelerConfig,
        AugmenterAgent, AugmenterConfig,
        QualityControl, QualityControlConfig,
        DataWriter, DataWriterConfig,
        DataStorage, DataStorageConfig,
    )
    from src.config_v2 import Settings
    print("‚úÖ –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    exit(1)


async def test_components():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    print("\n" + "="*60)
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    print("="*60)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    try:
        settings = Settings.load()
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ .env —Ñ–∞–π–ª –∏–∑ env.docker.example")
        return False
    
    # 1. ETL Test
    print("\nüì• –¢–µ—Å—Ç 1: ETL Processor")
    try:
        etl = ETLProcessor(ETLConfig(max_rows=10))
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π CSV
        test_csv = Path("test_data.csv")
        test_csv.write_text(
            "text,domain\n"
            "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞,house\n"
            "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ –≤ —à–∫–æ–ª–µ,payments\n"
            "—É–∑–Ω–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ,okc\n",
            encoding="utf-8"
        )
        
        df = etl.process_file(test_csv)
        print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        print(f"   üìä –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        test_csv.unlink()
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ ETL: {e}")
        return False
    
    # 2. Labeler Test
    print("\nüè∑Ô∏è  –¢–µ—Å—Ç 2: Labeler Agent")
    try:
        labeler_config = LabelerConfig(
            **settings.get_labeler_llm_config(),
            batch_size=5,
            rate_limit=0.5,
        )
        labeler = LabelerAgent(labeler_config)
        print("   ‚úÖ LabelerAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –¢–µ—Å—Ç–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        test_texts = [
            "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
            "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ",
            "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ"
        ]
        
        print("   üîÑ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã...")
        results = await labeler.classify_batch(test_texts[:2])  # –¢–æ–ª—å–∫–æ 2 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
        
        print(f"   ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {len(results)} —Ç–µ–∫—Å—Ç–æ–≤")
        for r in results:
            print(f"      ‚Ä¢ {r.text[:40]}... ‚Üí {r.domain_id} ({r.confidence:.2f})")
        
        stats = labeler.get_stats()
        print(f"   üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ Labeler: {e}")
        print(f"   üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ LLM_API_KEY –≤ .env —Ñ–∞–π–ª–µ")
        return False
    
    # 3. Quality Control Test
    print("\nüõ°Ô∏è  –¢–µ—Å—Ç 3: Quality Control")
    try:
        qc = QualityControl(QualityControlConfig())
        
        # –¢–µ—Å—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        original = "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞"
        
        test_cases = [
            ("–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á—ë—Ç—á–∏–∫–∞", "–ø–æ—á—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç"),  # –í—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            ("–ø–æ–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∏–±–æ—Ä–∞ —É—á–µ—Ç–∞", "—Ö–æ—Ä–æ—à–∞—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∞"),  # –°—Ä–µ–¥–Ω–µ–µ
            ("–∫—É–ø–∏—Ç—å —Ö–ª–µ–± –≤ –º–∞–≥–∞–∑–∏–Ω–µ", "—Å–æ–≤—Å–µ–º –¥—Ä—É–≥–æ–µ"),  # –ù–∏–∑–∫–æ–µ
        ]
        
        for synthetic, label in test_cases:
            metrics = qc.compute_similarity(original, synthetic)
            status = "‚úÖ" if metrics.is_valid else "‚ùå"
            print(f"   {status} {label}:")
            print(f"      Cosine: {metrics.cosine_similarity:.3f}")
            print(f"      Levenshtein: {metrics.levenshtein_distance} "
                  f"(ratio: {metrics.levenshtein_ratio:.3f})")
            if metrics.issues:
                print(f"      Issues: {', '.join(metrics.issues)}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ QualityControl: {e}")
        return False
    
    # 4. DataWriter Test
    print("\nüíæ –¢–µ—Å—Ç 4: Data Writer")
    try:
        writer_config = DataWriterConfig(
            output_dir=Path("test_output"),
            eval_fraction=0.2,
            balance_domains=False,
        )
        writer = DataWriter(writer_config)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_items = [
            {"text": "—Ç–µ–∫—Å—Ç 1", "domain_id": "house", "confidence": 0.9},
            {"text": "—Ç–µ–∫—Å—Ç 2", "domain_id": "payments", "confidence": 0.85},
            {"text": "—Ç–µ–∫—Å—Ç 3", "domain_id": "house", "confidence": 0.92},
            {"text": "—Ç–µ–∫—Å—Ç 4", "domain_id": "okc", "confidence": 0.88},
            {"text": "—Ç–µ–∫—Å—Ç 5", "domain_id": "payments", "confidence": 0.91},
        ]
        
        train_p, eval_p, stats = writer.write_datasets(test_items, dataset_name="test")
        
        print(f"   ‚úÖ Train: {stats.train_samples}, Eval: {stats.eval_samples}")
        print(f"   üìä Domains: {stats.domain_distribution}")
        
        # –û—á–∏—Å—Ç–∫–∞
        import shutil
        shutil.rmtree("test_output", ignore_errors=True)
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ DataWriter: {e}")
        return False
    
    # 5. DataStorage Test
    print("\nüì¶ –¢–µ—Å—Ç 5: Data Storage")
    try:
        storage_config = DataStorageConfig(
            storage_dir=Path("test_storage"),
            max_versions=10,
        )
        storage = DataStorage(storage_config)
        
        print("   ‚úÖ DataStorage –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        stats = storage.get_stats()
        print(f"   üìä Versions: {stats['total_versions']}, Size: {stats['total_size_mb']:.2f} MB")
        
        # –û—á–∏—Å—Ç–∫–∞
        import shutil
        shutil.rmtree("test_storage", ignore_errors=True)
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ DataStorage: {e}")
        return False
    
    return True


async def test_full_pipeline():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π pipeline end-to-end"""
    
    print("\n" + "="*60)
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ pipeline")
    print("="*60)
    
    try:
        settings = Settings.load()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        print("\nüìù –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        test_file = Path("test_logs.csv")
        test_file.write_text(
            "text,domain\n"
            "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞,house\n"
            "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è –≤–æ–¥—ã,house\n"
            "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ –≤ —à–∫–æ–ª–µ,payments\n"
            "–æ–ø–ª–∞—Ç–∏—Ç—å –∫—Ä—É–∂–æ–∫,payments\n"
            "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ,okc\n"
            "–∫–æ–≥–¥–∞ –æ—Ç–∫—Ä–æ–µ—Ç—Å—è —Å—Ç–∞–Ω—Ü–∏—è,okc\n",
            encoding="utf-8"
        )
        
        # 1. ETL
        print("\n1Ô∏è‚É£  ETL...")
        etl = ETLProcessor(ETLConfig(max_rows=100))
        df = etl.process_file(test_file)
        print(f"   ‚úÖ {len(df)} —Å—Ç—Ä–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
        
        # 2. Labeler - –≤–∞–ª–∏–¥–∞—Ü–∏—è
        print("\n2Ô∏è‚É£  Labeler - –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç–æ–∫...")
        labeler_config = LabelerConfig(
            **settings.get_labeler_llm_config(),
            batch_size=10,
            rate_limit=0.5,
        )
        labeler = LabelerAgent(labeler_config)
        
        results = await labeler.classify_dataframe(df, text_column="text")
        print(f"   ‚úÖ {len(results)} —Ç–µ–∫—Å—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–∫
        qc = QualityControl(QualityControlConfig())
        
        original_items = [
            {"text": row["text"], "domain_id": row.get("domain", "unknown")}
            for _, row in df.iterrows()
            if "domain" in row
        ]
        
        if original_items:
            validation = await qc.validate_existing_labels(original_items, labeler)
            correct = sum(1 for v in validation if v.is_correct)
            print(f"   üìä –í–∞–ª–∏–¥–∞—Ü–∏—è: {correct}/{len(validation)} –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö "
                  f"({correct/len(validation):.1%})")
        
        # 3. Augmenter (–º–∏–Ω–∏-—Ç–µ—Å—Ç - —Ç–æ–ª—å–∫–æ 2 –ø—Ä–∏–º–µ—Ä–∞)
        print("\n3Ô∏è‚É£  Augmenter - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏–∫–∏...")
        
        augmenter_config = AugmenterConfig(
            **settings.get_augmenter_llm_config(),
            variants_per_sample=2,  # –¢–æ–ª—å–∫–æ 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
            concurrency=2,
        )
        augmenter = AugmenterAgent(augmenter_config)
        
        high_conf = [r.dict() for r in results if r.confidence >= 0.7][:2]  # –¢–æ–ª—å–∫–æ 2 –ø—Ä–∏–º–µ—Ä–∞
        
        if high_conf:
            synthetic = await augmenter.augment_batch(high_conf)
            print(f"   ‚úÖ {len(synthetic)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")
            
            # 4. Quality Control
            print("\n4Ô∏è‚É£  Quality Control - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–µ—Ç–∏–∫–∏...")
            
            validated_synthetic = await qc.validate_and_label_synthetic(
                synthetic_items=[s.dict() for s in synthetic],
                original_items=high_conf,
                labeler_agent=labeler
            )
            
            print(f"   ‚úÖ {len(validated_synthetic)}/{len(synthetic)} –ø—Ä–æ—à–ª–æ –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞")
            
            if validated_synthetic:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
                for item in validated_synthetic[:2]:
                    qm = item.get("quality_metrics", {})
                    print(f"      ‚Ä¢ {item['text'][:50]}...")
                    print(f"        Cosine: {qm.get('cosine_similarity', 0):.3f}, "
                          f"Levenshtein: {qm.get('levenshtein_distance', 0)}")
        else:
            print("   ‚ö†Ô∏è  –ù–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
            validated_synthetic = []
        
        # 5. DataWriter
        print("\n5Ô∏è‚É£  DataWriter - —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        all_items = [r.dict() for r in results] + validated_synthetic
        
        writer_config = DataWriterConfig(
            output_dir=Path("test_pipeline_output"),
            eval_fraction=0.2,
            balance_domains=False,
        )
        writer = DataWriter(writer_config)
        
        train_p, eval_p, stats = writer.write_datasets(all_items, dataset_name="test")
        
        print(f"   ‚úÖ Train: {stats.train_samples}, Eval: {stats.eval_samples}")
        print(f"   üìä Domains: {stats.domain_distribution}")
        print(f"   üìä Quality score: {stats.quality_issues if stats.quality_issues else 'OK'}")
        
        # 6. DataStorage
        print("\n6Ô∏è‚É£  DataStorage - –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        
        storage_config = DataStorageConfig(
            storage_dir=Path("test_storage"),
            max_versions=10,
        )
        storage = DataStorage(storage_config)
        
        from src.pipeline.data_storage import VersionStatus
        version = storage.commit_version(
            train_path=train_p,
            eval_path=eval_p,
            description="Test pipeline run",
            status=VersionStatus.DRAFT,
            created_by="test_script"
        )
        
        print(f"   ‚úÖ Version created: {version.version_tag}")
        
        # –°–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π
        versions = storage.list_versions()
        print(f"   üìä Total versions: {len(versions)}")
        
        # –£—Å–ø–µ—Ö!
        print("\n" + "="*60)
        print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("="*60)
        
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        print("\nüßπ –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        import shutil
        test_file.unlink(missing_ok=True)
        shutil.rmtree("test_pipeline_output", ignore_errors=True)
        shutil.rmtree("test_storage", ignore_errors=True)
        print("   ‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ pipeline: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_quality_control_detailed():
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Quality Control"""
    
    print("\n" + "="*60)
    print("üî¨ –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Quality Control")
    print("="*60)
    
    qc = QualityControl(QualityControlConfig(
        min_cosine_similarity=0.3,
        max_cosine_similarity=0.95,
        max_levenshtein_ratio=0.8,
        min_levenshtein_changes=3,
    ))
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏
    test_cases = [
        {
            "original": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
            "synthetic": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á—ë—Ç—á–∏–∫–∞",
            "expected": "rejected_high_similarity",  # –ü–æ—á—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç
            "label": "–ü–æ—á—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç (1 —Å–∏–º–≤–æ–ª)"
        },
        {
            "original": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
            "synthetic": "–ø–æ–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∏–±–æ—Ä–∞ —É—á–µ—Ç–∞",
            "expected": "passed",  # –•–æ—Ä–æ—à–∞—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∞
            "label": "–•–æ—Ä–æ—à–∞—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∞"
        },
        {
            "original": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
            "synthetic": "–∫—É–ø–∏—Ç—å —Ö–ª–µ–± –≤ –º–∞–≥–∞–∑–∏–Ω–µ",
            "expected": "rejected_low_similarity",  # –°–æ–≤—Å–µ–º –¥—Ä—É–≥–æ–µ
            "label": "–°–æ–≤—Å–µ–º –¥—Ä—É–≥–æ–π —Å–º—ã—Å–ª"
        },
        {
            "original": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
            "synthetic": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞",
            "expected": "rejected_levenshtein",  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            "label": "–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π"
        },
    ]
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:\n")
    
    passed = 0
    failed = 0
    
    for i, test_case in enumerate(test_cases, 1):
        metrics = qc.compute_similarity(
            test_case["original"],
            test_case["synthetic"]
        )
        
        status = "‚úÖ PASS" if metrics.is_valid else "‚ùå FAIL"
        
        print(f"{i}. {test_case['label']}:")
        print(f"   Status: {status}")
        print(f"   Cosine similarity: {metrics.cosine_similarity:.3f}")
        print(f"   Levenshtein: {metrics.levenshtein_distance} "
              f"(ratio: {metrics.levenshtein_ratio:.3f})")
        
        if metrics.issues:
            print(f"   Issues: {', '.join(metrics.issues)}")
        
        if metrics.is_valid:
            passed += 1
        else:
            failed += 1
        
        print()
    
    print(f"üìä –ò—Ç–æ–≥–æ: {passed} passed, {failed} failed –∏–∑ {len(test_cases)}")
    
    return True


def test_imports():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã"""
    
    print("\n" + "="*60)
    print("üì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∏–º–ø–æ—Ä—Ç–æ–≤")
    print("="*60 + "\n")
    
    imports_to_test = [
        ("FastAPI", "from fastapi import FastAPI"),
        ("Pydantic", "from pydantic import BaseModel"),
        ("PydanticAI", "from pydantic_ai import Agent"),
        ("Pandas", "import pandas as pd"),
        ("OpenAI", "from openai import OpenAI"),
        ("sklearn", "from sklearn.feature_extraction.text import TfidfVectorizer"),
        ("httpx", "import httpx"),
        ("uvicorn", "import uvicorn"),
    ]
    
    all_ok = True
    
    for name, import_statement in imports_to_test:
        try:
            exec(import_statement)
            print(f"‚úÖ {name}")
        except ImportError as e:
            print(f"‚ùå {name}: {e}")
            all_ok = False
    
    if all_ok:
        print("\n‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
    else:
        print("\n‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        print("üí° –í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install -r requirements.txt")
    
    return all_ok


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print("\n" + "üß™ "*20)
    print("    ML DATA PIPELINE - –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï    ")
    print("üß™ "*20 + "\n")
    
    # –¢–µ—Å—Ç 1: –ò–º–ø–æ—Ä—Ç—ã
    if not test_imports():
        print("\n‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞")
        return
    
    # –¢–µ—Å—Ç 2: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    components_ok = await test_components()
    
    if not components_ok:
        print("\n‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏ —Ç–µ—Å—Ç")
        print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
        return
    
    # –¢–µ—Å—Ç 3: Quality Control –¥–µ—Ç–∞–ª—å–Ω–æ
    await test_quality_control_detailed()
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
    print("\n" + "üéâ "*20)
    print("    –í–°–ï –¢–ï–°–¢–´ –£–°–ü–ï–®–ù–û –ü–†–û–ô–î–ï–ù–´!    ")
    print("üéâ "*20 + "\n")
    
    print("‚úÖ –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    print("‚úÖ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –≤ production!")
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. docker-compose up -d")
    print("   2. curl http://localhost:8000/docs")
    print("   3. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ —á–µ—Ä–µ–∑ API\n")


if __name__ == "__main__":
    asyncio.run(main())

