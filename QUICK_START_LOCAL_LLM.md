# ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM (Mistral + Qwen)

**–ó–∞–∫—Ä—ã—Ç—ã–π –∫–æ–Ω—Ç—É—Ä –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö API - –≥–æ—Ç–æ–≤ –∑–∞ 10 –º–∏–Ω—É—Ç!**

---

## üöÄ –ó–∞–ø—É—Å–∫ (3 –∫–æ–º–∞–Ω–¥—ã)

```bash
# 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
cp docker-compose.local-llm.yml docker-compose.yml

# 2. –ó–∞–ø—É—Å–∫ (—Å–∫–∞—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)
docker-compose up -d

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ (–ø–æ–¥–æ–∂–¥–∏—Ç–µ ~5 –º–∏–Ω—É—Ç –ø–æ–∫–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è)
curl http://localhost:8080/health
```

**API —Ä–∞–±–æ—Ç–∞–µ—Ç:** http://localhost:8080  
**Swagger:** http://localhost:8080/docs

---

## üîß –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### Mistral –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:
```
http://localhost:8000 ‚Üê Labeler –∏—Å–ø–æ–ª—å–∑—É–µ—Ç
```

### Qwen –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
```
http://localhost:8001 ‚Üê Augmenter –∏—Å–ø–æ–ª—å–∑—É–µ—Ç
```

### ML Pipeline:
```
http://localhost:8080 ‚Üê –í–∞—à API
```

---

## üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã

### 1. Health Check

```bash
curl http://localhost:8080/health
```

–î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
```json
{
  "status": "healthy",
  "components": {
    "labeler": "ok",
    "augmenter": "ok",
    "quality_control": "ok"
  }
}
```

### 2. –¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

```bash
curl -X POST "http://localhost:8080/classify" \
  -H "Content-Type: application/json" \
  -d '{"texts": ["–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞"]}'
```

### 3. Swagger UI

–û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8080/docs –≤ –±—Ä–∞—É–∑–µ—Ä–µ

---

## ‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Docker** —Å GPU support
- **NVIDIA GPU** —Å –º–∏–Ω–∏–º—É–º 24GB VRAM (–¥–ª—è 2 –º–æ–¥–µ–ª–µ–π –ø–æ 7B)
- **–î–∏—Å–∫:** ~30GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (–º–æ–¥–µ–ª–∏ + –∫—ç—à)

---

## üéØ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Ollama (–ø—Ä–æ—â–µ)

–ï—Å–ª–∏ –Ω–µ—Ç GPU –∏–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ—â–µ:

```bash
# 1. –í docker-compose.yml –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Ollama:
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª–∏
docker-compose exec ollama ollama pull mistral:7b
docker-compose exec ollama ollama pull qwen2:7b

# 3. –í .env:
LLM_LABELER_API_BASE=http://ollama:11434/v1
LLM_LABELER_MODEL=mistral:7b

LLM_AUGMENTER_API_BASE=http://ollama:11434/v1
LLM_AUGMENTER_MODEL=qwen2:7b
```

---

## üìù –õ–æ–≥–∏

```bash
# –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã
docker-compose logs -f

# –¢–æ–ª—å–∫–æ pipeline
docker-compose logs -f ml-pipeline

# –¢–æ–ª—å–∫–æ LLM
docker-compose logs -f llm-labeler llm-augmenter
```

---

## üéâ –ì–æ—Ç–æ–≤–æ!

**–õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –∑–∞–∫—Ä—ã—Ç–æ–º –∫–æ–Ω—Ç—É—Ä–µ!** üîí

**–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** [LOCAL_LLM_SETUP.md](LOCAL_LLM_SETUP.md)

